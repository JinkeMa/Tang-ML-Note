{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.fixes import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import sklearn.preprocessing as preprosessing\n",
    "\n",
    "# 数据准备\n",
    "features = pd.read_csv('d:/GitRepos/data/temps.csv')\n",
    "features = pd.get_dummies(features)\n",
    "labels = np.array(features['actual'])\n",
    "features = features.drop(['year','actual'],axis=1)\n",
    "features = np.array(features)\n",
    "features = preprosessing.StandardScaler().fit_transform(features)\n",
    "features.shape\n",
    "# labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络搭建\n",
    "in_features = 13\n",
    "hidden_features = 128\n",
    "out_features = 1\n",
    "batch_size = 16\n",
    "mnn = nn.Sequential(\n",
    "    nn.Linear(in_features,hidden_features),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(hidden_features,out_features)\n",
    ")\n",
    "cost = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mnn.parameters(),lr = 0.001)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# mnn.to(device) \n",
    "losses = []\n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "    batch_loss = []\n",
    "    for start in range(0,len(features),batch_size):\n",
    "        end = start + batch_size if (start + batch_size < len(features)) else len(features)\n",
    "        xx = torch.tensor(features[start:end],dtype=torch.float,requires_grad=True)\n",
    "        yy = torch.tensor(labels[start:end],dtype=torch.float,requires_grad=True)\n",
    "        predict = mnn(xx)\n",
    "        loss = cost(predict,yy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.data.numpy())\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        losses.append(batch_loss)\n",
    "        print(\"epoch {0},loss {1}\".format(epoch,np.mean(batch_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Program2\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([348])) that is different to the input size (torch.Size([348, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss147.23590087890625\n",
      "loss141.72596740722656\n",
      "loss140.27464294433594\n",
      "loss139.70663452148438\n",
      "loss139.4272003173828\n",
      "loss139.26983642578125\n",
      "loss139.1649169921875\n",
      "loss139.091064453125\n",
      "loss139.03555297851562\n",
      "loss138.9927978515625\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import forward_ad\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "#data\n",
    "features = pd.read_csv('d:/GitRepos/data/temps.csv')\n",
    "features = pd.get_dummies(features)\n",
    "features.head()\n",
    "y_labels = torch.tensor(np.array(features['actual']),dtype=torch.float,requires_grad=True)\n",
    "features = features.drop(['actual','friend'],axis=1)\n",
    "features = preprocessing.StandardScaler().fit_transform(np.array(features))\n",
    "x_trains = torch.tensor(features,dtype=torch.float,requires_grad=True)\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(13,128,bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,1,bias=True)\n",
    ")\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "cost= torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    epoch += 1\n",
    "    #zerograd\n",
    "    optimizer.zero_grad()\n",
    "    #forward\n",
    "    pred = model(x_trains)\n",
    "    #cost\n",
    "    loss = cost(pred,y_labels)\n",
    "    #backward\n",
    "    loss.backward()\n",
    "    #\n",
    "    if epoch % 100 == 0:\n",
    "        print('loss{}'.format(loss))\n",
    "    #optim\n",
    "    optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e32618030883af29da10316c76c83da9a02f65dadf9a9b09d160d0d4f5840e5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
