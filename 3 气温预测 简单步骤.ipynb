{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348, 13)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.fixes import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import sklearn.preprocessing as preprosessing\n",
    "\n",
    "# 数据准备\n",
    "features = pd.read_csv('d:/GitRepos/data/temps.csv')\n",
    "features = pd.get_dummies(features)\n",
    "labels = np.array(features['actual'])\n",
    "features = features.drop(['year','actual'],axis=1)\n",
    "features = np.array(features)\n",
    "features = preprosessing.StandardScaler().fit_transform(features)\n",
    "features.shape\n",
    "# labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Program2\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "e:\\Program2\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([12, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0,loss 3862.596923828125\n",
      "epoch 100,loss 37.939170837402344\n",
      "epoch 200,loss 35.660274505615234\n",
      "epoch 300,loss 35.2928466796875\n",
      "epoch 400,loss 35.11722183227539\n",
      "epoch 500,loss 34.9793586730957\n",
      "epoch 600,loss 34.85498809814453\n"
     ]
    }
   ],
   "source": [
    "# 网络搭建\n",
    "in_features = 13\n",
    "hidden_features = 128\n",
    "out_features = 1\n",
    "batch_size = 16\n",
    "mnn = nn.Sequential(\n",
    "    nn.Linear(in_features,hidden_features),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(hidden_features,out_features)\n",
    ")\n",
    "cost = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mnn.parameters(),lr = 0.001)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# mnn.to(device) \n",
    "losses = []\n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "    batch_loss = []\n",
    "    for start in range(0,len(features),batch_size):\n",
    "        end = start + batch_size if (start + batch_size < len(features)) else len(features)\n",
    "        xx = torch.tensor(features[start:end],dtype=torch.float,requires_grad=True)\n",
    "        yy = torch.tensor(labels[start:end],dtype=torch.float,requires_grad=True)\n",
    "        predict = mnn(xx)\n",
    "        loss = cost(predict,yy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.data.numpy())\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        losses.append(batch_loss)\n",
    "        print(\"epoch {0},loss {1}\".format(epoch,np.mean(batch_loss)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e32618030883af29da10316c76c83da9a02f65dadf9a9b09d160d0d4f5840e5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
